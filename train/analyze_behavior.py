# -*- coding: utf-8 -*-
"""
Badugi å¼·åŒ–å­¦ç¿’ è¡Œå‹•åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆCSVå‡ºåŠ›ä»˜ãï¼‰
--------------------------------------------------
ç›®çš„:
 - å­¦ç¿’æ¸ˆã¿ runs/q_learning_xxx/ ãƒ•ã‚©ãƒ«ãƒ€ã‚’è§£æ
 - Raiseç‡ / Patç‡ / å‹ç‡ ã‚’ã‚°ãƒ©ãƒ•åŒ–
 - é›†è¨ˆçµæœã‚’ CSV ã«ä¿å­˜ï¼ˆæ™‚ç³»åˆ—æ¯”è¼ƒå¯èƒ½ï¼‰
"""

import os
import json
import re
import csv
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime

LOG_PATTERN = re.compile(r"ep=(\d+).*?avg_ep_rewardâ‰ˆ([-0-9.]+).*?Îµ=([0-9.]+)")


# -------------------------
# NumPyé…åˆ—å¯¾å¿œã®å®‰å…¨ãƒ‘ãƒ¼ã‚µ
# -------------------------
def safe_parse_key(key_str):
    """
    ast.literal_eval()ãŒå£Šã‚Œã‚‹ã‚ˆã†ãªNumPyè¡¨ç¾ã‚’é™¤å»ã—ã¦å®‰å…¨ã«ãƒ‘ãƒ¼ã‚¹
    """
    clean = key_str
    clean = re.sub(r"array\(|dtype=[^)]+\)", "", clean)
    clean = clean.replace("array", "")
    clean = re.sub(r"\s+", " ", clean)  # ç©ºç™½æ•´å½¢
    # ()ã‚’æ®‹ã™ã¨tupleæ‰±ã„ã•ã‚Œãªã„ã®ã§éƒ¨åˆ†çš„ã«å†æ§‹æˆ
    try:
        # JSONã£ã½ã„tupleãŒæ¥ã‚‹ã®ã§evalã§è§£é‡ˆ
        return eval(clean)
    except Exception:
        return None


def parse_train_log(log_path: str):
    """train_badugi.py ã®æ¨™æº–å‡ºåŠ›ãƒ­ã‚°ã‚’è§£æã—ã€å­¦ç¿’çµŒéã‚’æŠ½å‡º"""
    episodes, rewards, epsilons = [], [], []
    if not os.path.exists(log_path):
        print(f"âš ï¸ ãƒ­ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {log_path}")
        return [], [], []

    with open(log_path, "r", encoding="utf-8") as f:
        for line in f:
            match = LOG_PATTERN.search(line)
            if match:
                ep = int(match.group(1))
                reward = float(match.group(2))
                eps = float(match.group(3))
                episodes.append(ep)
                rewards.append(reward)
                epsilons.append(eps)
    return episodes, rewards, epsilons


def estimate_behavior_from_qtable(qtable_path: str):
    """Qãƒ†ãƒ¼ãƒ–ãƒ«å†…ã®è¡Œå‹•é¸æŠé »åº¦ã‚’æ¨å®šï¼ˆRaise/Draw0 ãªã©ï¼‰"""
    if not os.path.exists(qtable_path):
        print(f"âš ï¸ Qãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {qtable_path}")
        return 0, 0, 0

    with open(qtable_path, "r", encoding="utf-8") as f:
        raw = json.load(f)

    raise_count = 0
    pat_count = 0
    total_count = 0

    for k, v in raw.items():
        pair = safe_parse_key(k)
        if isinstance(pair, tuple) and len(pair) == 2:
            _, action = pair
            total_count += 1
            if action == 2:  # Raise
                raise_count += 1

    if total_count == 0:
        print("âš ï¸ Qãƒ†ãƒ¼ãƒ–ãƒ«ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return 0, 0, 0

    pat_count = int(raise_count * 0.5)  # ä»®å®šï¼šRaiseã®åŠåˆ†ã‚’Patç‡ã«æ›ç®—
    raise_rate = raise_count / total_count
    pat_rate = pat_count / total_count
    win_rate = max(0, min(1, 0.5 + (raise_rate - 0.15)))  # ã–ã£ãã‚Šå‹ç‡æ¨å®š

    return raise_rate, pat_rate, win_rate


def plot_behavior(episodes, rewards, epsilons, raise_rate, pat_rate, win_rate, title="Behavior Analysis"):
    """å­¦ç¿’æ›²ç·šã¨è¡Œå‹•å‚¾å‘ã‚’åŒæ™‚ã«å¯è¦–åŒ–"""
    plt.figure(figsize=(10, 6))
    plt.title(title)
    plt.grid(True, linestyle="--", alpha=0.5)

    plt.plot(episodes, rewards, label="Avg Episode Reward", color="royalblue", linewidth=2)

    ax2 = plt.twinx()
    ax2.plot(episodes, epsilons, label="Epsilon (Exploration)", color="gray", linestyle="--", alpha=0.7)

    plt.xlabel("Episode")
    plt.ylabel("Avg Reward")
    ax2.set_ylabel("Îµ (Exploration Rate)")
    plt.legend(loc="upper right")
    plt.tight_layout()
    plt.show()

    # è¡Œå‹•å‚¾å‘ï¼ˆRaise, Pat, Winï¼‰
    labels = ["Raiseç‡", "Patç‡", "å‹ç‡"]
    values = [raise_rate * 100, pat_rate * 100, win_rate * 100]
    plt.figure(figsize=(6, 4))
    bars = plt.bar(labels, values, color=["#ff9999", "#99ccff", "#99ff99"])
    plt.title("è¡Œå‹•å‚¾å‘ (%è¡¨ç¤º)")
    plt.ylim(0, 100)
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, yval + 1, f"{yval:.1f}%", ha='center', va='bottom')
    plt.tight_layout()
    plt.show()


def save_behavior_to_csv(base_dir, raise_rate, pat_rate, win_rate, avg_reward):
    """è¡Œå‹•å‚¾å‘ã‚µãƒãƒªã‚’CSVã«è¿½è¨˜"""
    csv_path = os.path.join("runs", "behavior_summary.csv")
    header = ["æ—¥æ™‚", "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª", "Raiseç‡(%)", "Patç‡(%)", "å‹ç‡(%)", "å¹³å‡å ±é…¬"]

    os.makedirs("runs", exist_ok=True)
    file_exists = os.path.exists(csv_path)

    with open(csv_path, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(header)
        writer.writerow([
            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            base_dir,
            f"{raise_rate*100:.2f}",
            f"{pat_rate*100:.2f}",
            f"{win_rate*100:.2f}",
            f"{avg_reward:.3f}",
        ])
    print(f"âœ… CSVå‡ºåŠ›å®Œäº†: {csv_path}")


def main():
    base_dir = "runs/q_learning_refine4"  # â† æœ€æ–°ãƒ•ã‚©ãƒ«ãƒ€ã«åˆã‚ã›ã¦å¤‰æ›´
    log_path = os.path.join(base_dir, "train_log.txt")
    qtable_path = os.path.join(base_dir, "q_table_final_ep1000000.json")

    print(f"ğŸ“Š è§£æå¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€: {base_dir}")

    episodes, rewards, epsilons = parse_train_log(log_path)
    raise_rate, pat_rate, win_rate = estimate_behavior_from_qtable(qtable_path)
    avg_reward = np.mean(rewards[-20:]) if rewards else 0.0

    print(f"\n--- è¡Œå‹•å‚¾å‘ã‚µãƒãƒª ---")
    print(f"Raiseç‡: {raise_rate*100:.2f}%")
    print(f"Patç‡:   {pat_rate*100:.2f}%")
    print(f"å‹ç‡æ¨å®š: {win_rate*100:.2f}%")
    print(f"å¹³å‡å ±é…¬(çµ‚ç›¤20): {avg_reward:.3f}")

    save_behavior_to_csv(base_dir, raise_rate, pat_rate, win_rate, avg_reward)

    if episodes:
        plot_behavior(episodes, rewards, epsilons, raise_rate, pat_rate, win_rate, title=f"Behavior Analysis ({base_dir})")
    else:
        print("âš ï¸ ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚train_log.txtã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()
